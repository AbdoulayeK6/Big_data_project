{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c626831d-f921-451a-a37a-8c4845d0a3d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Créer une session Spark\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceb4c8c5-b1bd-4454-a4c9-f4c402a78ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Charger le fichier texte dans un RDD\n",
    "rdd = spark.sparkContext.textFile(\"/FileStore/tables/shakespeare.txt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e478434b-b687-422a-8f78-4cfa4127c906",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transformer les lignes en mots et compter les occurrences\n",
    "word_counts = (\n",
    "    rdd.flatMap(lambda line: line.split(\" \"))  # Diviser les lignes en mots\n",
    "    .map(lambda word: (word.lower(), 1))      # Convertir en minuscule et mapper (mot, 1)\n",
    "    .reduceByKey(lambda a, b: a + b)          # Réduire par clé pour compter les mots\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3864da53-6ec7-49d0-908f-199593b2fc52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Trier par nombre d’occurrences et afficher les 10 plus fréquents\n",
    "top_words = word_counts.sortBy(lambda x: x[1], ascending=False).take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27e43214-d066-4276-b801-2b6a89ba2af6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 559\nand: 490\nthe: 431\nto: 408\nmy: 390\nof: 368\ni: 335\nin: 322\nthat: 320\nthy: 287\n"
     ]
    }
   ],
   "source": [
    "# Afficher les résultats\n",
    "for word, count in top_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd8a290d-1005-4d28-9d2d-30eaf96229f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://repos.azul.com/zulu/deb stable InRelease\nHit:2 http://archive.ubuntu.com/ubuntu focal InRelease\nHit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\nHit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\nHit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\nHit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\nReading package lists...\nReading package lists...\nBuilding dependency tree...\nReading state information...\nE: Unable to locate package hadoop\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y hadoop\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4286663607349838,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Mini_project_Apache_Spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}